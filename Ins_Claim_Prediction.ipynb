{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9e473bb",
   "metadata": {},
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0426023c",
   "metadata": {},
   "source": [
    "Task 1:-Create a predictive model which will help the insurance marketing team to know which customer will buy the product.\n",
    "\n",
    "Task 2:-Suggestions to the Insurance market team to make  customers  buy the product.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ac25e4",
   "metadata": {},
   "source": [
    "# Project Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb960314",
   "metadata": {},
   "source": [
    "The Data science project which is given here is to predict the model for the insurance claim. The project goal is to predict the model which will help the insurance marketing team to know which customer will buy the product. The need for an accurate and efficient solution to the insurance marketing team for the customers to buy the product."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4a32dc",
   "metadata": {},
   "source": [
    "The given data has the 595212 data to perform a higher level machine learning where it is well structured. The features present in the data are 59 in total. The Shape of the data is 595212x59. The 59 features that belongs to similar groupings are tagged as ind, reg, car, calc, cat means categorical columns and bin means binary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df37112",
   "metadata": {},
   "source": [
    "Due to privacy concerns, the company has not shared the names of the features. so EDA part is skipped as mentioned in the document and moving directly towards the modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f955ed8",
   "metadata": {},
   "source": [
    "The dataset is a complete labelled data and categorical which decides the machine learning algorithm to be used.PCA technique should be used for feature extraction since this is large dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19159f29",
   "metadata": {},
   "source": [
    "The machine learning model which is used in this project is Logistic Regression and Random Forest Classifier which predicted the nearby higher accuracy of 96%. Since it is categorical labelled data, it has to go through the classifier machine learning techniques which will be suitable for this structured data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa164ef",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf6b1327",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sb\n",
    "# Import and suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eeef2c",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07970f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595207</th>\n",
       "      <td>1488013</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595208</th>\n",
       "      <td>1488016</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595209</th>\n",
       "      <td>1488017</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595210</th>\n",
       "      <td>1488021</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595211</th>\n",
       "      <td>1488027</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>595212 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  target  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  \\\n",
       "0             7       0          2              2          5              1   \n",
       "1             9       0          1              1          7              0   \n",
       "2            13       0          5              4          9              1   \n",
       "3            16       0          0              1          2              0   \n",
       "4            17       0          0              2          0              1   \n",
       "...         ...     ...        ...            ...        ...            ...   \n",
       "595207  1488013       0          3              1         10              0   \n",
       "595208  1488016       0          5              1          3              0   \n",
       "595209  1488017       0          1              1         10              0   \n",
       "595210  1488021       0          5              2          3              1   \n",
       "595211  1488027       0          0              1          8              0   \n",
       "\n",
       "        ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ...  \\\n",
       "0                   0              0              1              0  ...   \n",
       "1                   0              0              0              1  ...   \n",
       "2                   0              0              0              1  ...   \n",
       "3                   0              1              0              0  ...   \n",
       "4                   0              1              0              0  ...   \n",
       "...               ...            ...            ...            ...  ...   \n",
       "595207              0              0              0              0  ...   \n",
       "595208              0              0              0              0  ...   \n",
       "595209              0              1              0              0  ...   \n",
       "595210              0              0              0              1  ...   \n",
       "595211              0              1              0              0  ...   \n",
       "\n",
       "        ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
       "0                9           1           5           8               0   \n",
       "1                3           1           1           9               0   \n",
       "2                4           2           7           7               0   \n",
       "3                2           2           4           9               0   \n",
       "4                3           1           1           3               0   \n",
       "...            ...         ...         ...         ...             ...   \n",
       "595207           4           1           9           6               0   \n",
       "595208           4           1           3           8               1   \n",
       "595209           3           2           2           6               0   \n",
       "595210           4           1           4           2               0   \n",
       "595211           4           4           3           8               0   \n",
       "\n",
       "        ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "0                    1               1               0               0   \n",
       "1                    1               1               0               1   \n",
       "2                    1               1               0               1   \n",
       "3                    0               0               0               0   \n",
       "4                    0               0               1               1   \n",
       "...                ...             ...             ...             ...   \n",
       "595207               1               1               0               1   \n",
       "595208               0               1               0               1   \n",
       "595209               0               1               0               0   \n",
       "595210               1               1               1               0   \n",
       "595211               1               0               0               0   \n",
       "\n",
       "        ps_calc_20_bin  \n",
       "0                    1  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "...                ...  \n",
       "595207               1  \n",
       "595208               1  \n",
       "595209               0  \n",
       "595210               0  \n",
       "595211               0  \n",
       "\n",
       "[595212 rows x 59 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading the data\n",
    "ins = pd.read_csv(\"train.csv\")\n",
    "ins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d46ff66",
   "metadata": {},
   "source": [
    "# Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "462d5735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(595212, 59)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dimensions of the data\n",
    "ins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75b8a3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 595212 entries, 0 to 595211\n",
      "Data columns (total 59 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   id              595212 non-null  int64  \n",
      " 1   target          595212 non-null  int64  \n",
      " 2   ps_ind_01       595212 non-null  int64  \n",
      " 3   ps_ind_02_cat   595212 non-null  int64  \n",
      " 4   ps_ind_03       595212 non-null  int64  \n",
      " 5   ps_ind_04_cat   595212 non-null  int64  \n",
      " 6   ps_ind_05_cat   595212 non-null  int64  \n",
      " 7   ps_ind_06_bin   595212 non-null  int64  \n",
      " 8   ps_ind_07_bin   595212 non-null  int64  \n",
      " 9   ps_ind_08_bin   595212 non-null  int64  \n",
      " 10  ps_ind_09_bin   595212 non-null  int64  \n",
      " 11  ps_ind_10_bin   595212 non-null  int64  \n",
      " 12  ps_ind_11_bin   595212 non-null  int64  \n",
      " 13  ps_ind_12_bin   595212 non-null  int64  \n",
      " 14  ps_ind_13_bin   595212 non-null  int64  \n",
      " 15  ps_ind_14       595212 non-null  int64  \n",
      " 16  ps_ind_15       595212 non-null  int64  \n",
      " 17  ps_ind_16_bin   595212 non-null  int64  \n",
      " 18  ps_ind_17_bin   595212 non-null  int64  \n",
      " 19  ps_ind_18_bin   595212 non-null  int64  \n",
      " 20  ps_reg_01       595212 non-null  float64\n",
      " 21  ps_reg_02       595212 non-null  float64\n",
      " 22  ps_reg_03       595212 non-null  float64\n",
      " 23  ps_car_01_cat   595212 non-null  int64  \n",
      " 24  ps_car_02_cat   595212 non-null  int64  \n",
      " 25  ps_car_03_cat   595212 non-null  int64  \n",
      " 26  ps_car_04_cat   595212 non-null  int64  \n",
      " 27  ps_car_05_cat   595212 non-null  int64  \n",
      " 28  ps_car_06_cat   595212 non-null  int64  \n",
      " 29  ps_car_07_cat   595212 non-null  int64  \n",
      " 30  ps_car_08_cat   595212 non-null  int64  \n",
      " 31  ps_car_09_cat   595212 non-null  int64  \n",
      " 32  ps_car_10_cat   595212 non-null  int64  \n",
      " 33  ps_car_11_cat   595212 non-null  int64  \n",
      " 34  ps_car_11       595212 non-null  int64  \n",
      " 35  ps_car_12       595212 non-null  float64\n",
      " 36  ps_car_13       595212 non-null  float64\n",
      " 37  ps_car_14       595212 non-null  float64\n",
      " 38  ps_car_15       595212 non-null  float64\n",
      " 39  ps_calc_01      595212 non-null  float64\n",
      " 40  ps_calc_02      595212 non-null  float64\n",
      " 41  ps_calc_03      595212 non-null  float64\n",
      " 42  ps_calc_04      595212 non-null  int64  \n",
      " 43  ps_calc_05      595212 non-null  int64  \n",
      " 44  ps_calc_06      595212 non-null  int64  \n",
      " 45  ps_calc_07      595212 non-null  int64  \n",
      " 46  ps_calc_08      595212 non-null  int64  \n",
      " 47  ps_calc_09      595212 non-null  int64  \n",
      " 48  ps_calc_10      595212 non-null  int64  \n",
      " 49  ps_calc_11      595212 non-null  int64  \n",
      " 50  ps_calc_12      595212 non-null  int64  \n",
      " 51  ps_calc_13      595212 non-null  int64  \n",
      " 52  ps_calc_14      595212 non-null  int64  \n",
      " 53  ps_calc_15_bin  595212 non-null  int64  \n",
      " 54  ps_calc_16_bin  595212 non-null  int64  \n",
      " 55  ps_calc_17_bin  595212 non-null  int64  \n",
      " 56  ps_calc_18_bin  595212 non-null  int64  \n",
      " 57  ps_calc_19_bin  595212 non-null  int64  \n",
      " 58  ps_calc_20_bin  595212 non-null  int64  \n",
      "dtypes: float64(10), int64(49)\n",
      "memory usage: 267.9 MB\n"
     ]
    }
   ],
   "source": [
    "#dtypes of the data\n",
    "ins.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "528e5bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.952120e+05</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.438036e+05</td>\n",
       "      <td>0.036448</td>\n",
       "      <td>1.900378</td>\n",
       "      <td>1.358943</td>\n",
       "      <td>4.423318</td>\n",
       "      <td>0.416794</td>\n",
       "      <td>0.405188</td>\n",
       "      <td>0.393742</td>\n",
       "      <td>0.257033</td>\n",
       "      <td>0.163921</td>\n",
       "      <td>...</td>\n",
       "      <td>5.441382</td>\n",
       "      <td>1.441918</td>\n",
       "      <td>2.872288</td>\n",
       "      <td>7.539026</td>\n",
       "      <td>0.122427</td>\n",
       "      <td>0.627840</td>\n",
       "      <td>0.554182</td>\n",
       "      <td>0.287182</td>\n",
       "      <td>0.349024</td>\n",
       "      <td>0.153318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.293678e+05</td>\n",
       "      <td>0.187401</td>\n",
       "      <td>1.983789</td>\n",
       "      <td>0.664594</td>\n",
       "      <td>2.699902</td>\n",
       "      <td>0.493311</td>\n",
       "      <td>1.350642</td>\n",
       "      <td>0.488579</td>\n",
       "      <td>0.436998</td>\n",
       "      <td>0.370205</td>\n",
       "      <td>...</td>\n",
       "      <td>2.332871</td>\n",
       "      <td>1.202963</td>\n",
       "      <td>1.694887</td>\n",
       "      <td>2.746652</td>\n",
       "      <td>0.327779</td>\n",
       "      <td>0.483381</td>\n",
       "      <td>0.497056</td>\n",
       "      <td>0.452447</td>\n",
       "      <td>0.476662</td>\n",
       "      <td>0.360295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.719915e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.435475e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.115549e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.488027e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id         target      ps_ind_01  ps_ind_02_cat  \\\n",
       "count  5.952120e+05  595212.000000  595212.000000  595212.000000   \n",
       "mean   7.438036e+05       0.036448       1.900378       1.358943   \n",
       "std    4.293678e+05       0.187401       1.983789       0.664594   \n",
       "min    7.000000e+00       0.000000       0.000000      -1.000000   \n",
       "25%    3.719915e+05       0.000000       0.000000       1.000000   \n",
       "50%    7.435475e+05       0.000000       1.000000       1.000000   \n",
       "75%    1.115549e+06       0.000000       3.000000       2.000000   \n",
       "max    1.488027e+06       1.000000       7.000000       4.000000   \n",
       "\n",
       "           ps_ind_03  ps_ind_04_cat  ps_ind_05_cat  ps_ind_06_bin  \\\n",
       "count  595212.000000  595212.000000  595212.000000  595212.000000   \n",
       "mean        4.423318       0.416794       0.405188       0.393742   \n",
       "std         2.699902       0.493311       1.350642       0.488579   \n",
       "min         0.000000      -1.000000      -1.000000       0.000000   \n",
       "25%         2.000000       0.000000       0.000000       0.000000   \n",
       "50%         4.000000       0.000000       0.000000       0.000000   \n",
       "75%         6.000000       1.000000       0.000000       1.000000   \n",
       "max        11.000000       1.000000       6.000000       1.000000   \n",
       "\n",
       "       ps_ind_07_bin  ps_ind_08_bin  ...     ps_calc_11     ps_calc_12  \\\n",
       "count  595212.000000  595212.000000  ...  595212.000000  595212.000000   \n",
       "mean        0.257033       0.163921  ...       5.441382       1.441918   \n",
       "std         0.436998       0.370205  ...       2.332871       1.202963   \n",
       "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "25%         0.000000       0.000000  ...       4.000000       1.000000   \n",
       "50%         0.000000       0.000000  ...       5.000000       1.000000   \n",
       "75%         1.000000       0.000000  ...       7.000000       2.000000   \n",
       "max         1.000000       1.000000  ...      19.000000      10.000000   \n",
       "\n",
       "          ps_calc_13     ps_calc_14  ps_calc_15_bin  ps_calc_16_bin  \\\n",
       "count  595212.000000  595212.000000   595212.000000   595212.000000   \n",
       "mean        2.872288       7.539026        0.122427        0.627840   \n",
       "std         1.694887       2.746652        0.327779        0.483381   \n",
       "min         0.000000       0.000000        0.000000        0.000000   \n",
       "25%         2.000000       6.000000        0.000000        0.000000   \n",
       "50%         3.000000       7.000000        0.000000        1.000000   \n",
       "75%         4.000000       9.000000        0.000000        1.000000   \n",
       "max        13.000000      23.000000        1.000000        1.000000   \n",
       "\n",
       "       ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  ps_calc_20_bin  \n",
       "count   595212.000000   595212.000000   595212.000000   595212.000000  \n",
       "mean         0.554182        0.287182        0.349024        0.153318  \n",
       "std          0.497056        0.452447        0.476662        0.360295  \n",
       "min          0.000000        0.000000        0.000000        0.000000  \n",
       "25%          0.000000        0.000000        0.000000        0.000000  \n",
       "50%          1.000000        0.000000        0.000000        0.000000  \n",
       "75%          1.000000        1.000000        1.000000        0.000000  \n",
       "max          1.000000        1.000000        1.000000        1.000000  \n",
       "\n",
       "[8 rows x 59 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Summary Statistics\n",
    "ins.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5867e6d",
   "metadata": {},
   "source": [
    "Based on understanding the data, we have 59 features. So we need to perform feature extraction to avoid complex model.\n",
    "PCA technique will help to reducing dimensions and also it helps to addressing dimensionality curse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdc7529",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dda3b7",
   "metadata": {},
   "source": [
    "PCA is effected by scale so we need to scale the features in the data before using PCA. we can transform the data onto unit scale (mean = 0 and variance = 1) for better performance. Scikit-Learn's StandardScaler helps standardize the dataset’s features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaf09964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'target', 'ps_ind_01', 'ps_ind_02_cat', 'ps_ind_03',\n",
       "       'ps_ind_04_cat', 'ps_ind_05_cat', 'ps_ind_06_bin', 'ps_ind_07_bin',\n",
       "       'ps_ind_08_bin', 'ps_ind_09_bin', 'ps_ind_10_bin', 'ps_ind_11_bin',\n",
       "       'ps_ind_12_bin', 'ps_ind_13_bin', 'ps_ind_14', 'ps_ind_15',\n",
       "       'ps_ind_16_bin', 'ps_ind_17_bin', 'ps_ind_18_bin', 'ps_reg_01',\n",
       "       'ps_reg_02', 'ps_reg_03', 'ps_car_01_cat', 'ps_car_02_cat',\n",
       "       'ps_car_03_cat', 'ps_car_04_cat', 'ps_car_05_cat', 'ps_car_06_cat',\n",
       "       'ps_car_07_cat', 'ps_car_08_cat', 'ps_car_09_cat', 'ps_car_10_cat',\n",
       "       'ps_car_11_cat', 'ps_car_11', 'ps_car_12', 'ps_car_13', 'ps_car_14',\n",
       "       'ps_car_15', 'ps_calc_01', 'ps_calc_02', 'ps_calc_03', 'ps_calc_04',\n",
       "       'ps_calc_05', 'ps_calc_06', 'ps_calc_07', 'ps_calc_08', 'ps_calc_09',\n",
       "       'ps_calc_10', 'ps_calc_11', 'ps_calc_12', 'ps_calc_13', 'ps_calc_14',\n",
       "       'ps_calc_15_bin', 'ps_calc_16_bin', 'ps_calc_17_bin', 'ps_calc_18_bin',\n",
       "       'ps_calc_19_bin', 'ps_calc_20_bin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking features\n",
    "ins.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "324551fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['target', 'ps_ind_01', 'ps_ind_02_cat', 'ps_ind_03', 'ps_ind_04_cat',\n",
       "       'ps_ind_05_cat', 'ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin',\n",
       "       'ps_ind_09_bin', 'ps_ind_10_bin', 'ps_ind_11_bin', 'ps_ind_12_bin',\n",
       "       'ps_ind_13_bin', 'ps_ind_14', 'ps_ind_15', 'ps_ind_16_bin',\n",
       "       'ps_ind_17_bin', 'ps_ind_18_bin', 'ps_reg_01', 'ps_reg_02', 'ps_reg_03',\n",
       "       'ps_car_01_cat', 'ps_car_02_cat', 'ps_car_03_cat', 'ps_car_04_cat',\n",
       "       'ps_car_05_cat', 'ps_car_06_cat', 'ps_car_07_cat', 'ps_car_08_cat',\n",
       "       'ps_car_09_cat', 'ps_car_10_cat', 'ps_car_11_cat', 'ps_car_11',\n",
       "       'ps_car_12', 'ps_car_13', 'ps_car_14', 'ps_car_15', 'ps_calc_01',\n",
       "       'ps_calc_02', 'ps_calc_03', 'ps_calc_04', 'ps_calc_05', 'ps_calc_06',\n",
       "       'ps_calc_07', 'ps_calc_08', 'ps_calc_09', 'ps_calc_10', 'ps_calc_11',\n",
       "       'ps_calc_12', 'ps_calc_13', 'ps_calc_14', 'ps_calc_15_bin',\n",
       "       'ps_calc_16_bin', 'ps_calc_17_bin', 'ps_calc_18_bin', 'ps_calc_19_bin',\n",
       "       'ps_calc_20_bin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing unwanted features\n",
    "ins.drop(['id'],axis=1,inplace=True)\n",
    "ins.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db10c4ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(595212, 58)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dimensions of the data\n",
    "ins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f203ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>ps_ind_10_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595207</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595208</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595209</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595210</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595211</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>595212 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  ps_ind_05_cat  \\\n",
       "0               2              2          5              1              0   \n",
       "1               1              1          7              0              0   \n",
       "2               5              4          9              1              0   \n",
       "3               0              1          2              0              0   \n",
       "4               0              2          0              1              0   \n",
       "...           ...            ...        ...            ...            ...   \n",
       "595207          3              1         10              0              0   \n",
       "595208          5              1          3              0              0   \n",
       "595209          1              1         10              0              0   \n",
       "595210          5              2          3              1              0   \n",
       "595211          0              1          8              0              0   \n",
       "\n",
       "        ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ps_ind_09_bin  \\\n",
       "0                   0              1              0              0   \n",
       "1                   0              0              1              0   \n",
       "2                   0              0              1              0   \n",
       "3                   1              0              0              0   \n",
       "4                   1              0              0              0   \n",
       "...               ...            ...            ...            ...   \n",
       "595207              0              0              0              1   \n",
       "595208              0              0              0              1   \n",
       "595209              1              0              0              0   \n",
       "595210              0              0              1              0   \n",
       "595211              1              0              0              0   \n",
       "\n",
       "        ps_ind_10_bin  ...  ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  \\\n",
       "0                   0  ...           9           1           5           8   \n",
       "1                   0  ...           3           1           1           9   \n",
       "2                   0  ...           4           2           7           7   \n",
       "3                   0  ...           2           2           4           9   \n",
       "4                   0  ...           3           1           1           3   \n",
       "...               ...  ...         ...         ...         ...         ...   \n",
       "595207              0  ...           4           1           9           6   \n",
       "595208              0  ...           4           1           3           8   \n",
       "595209              0  ...           3           2           2           6   \n",
       "595210              0  ...           4           1           4           2   \n",
       "595211              0  ...           4           4           3           8   \n",
       "\n",
       "        ps_calc_15_bin  ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  \\\n",
       "0                    0               1               1               0   \n",
       "1                    0               1               1               0   \n",
       "2                    0               1               1               0   \n",
       "3                    0               0               0               0   \n",
       "4                    0               0               0               1   \n",
       "...                ...             ...             ...             ...   \n",
       "595207               0               1               1               0   \n",
       "595208               1               0               1               0   \n",
       "595209               0               0               1               0   \n",
       "595210               0               1               1               1   \n",
       "595211               0               1               0               0   \n",
       "\n",
       "        ps_calc_19_bin  ps_calc_20_bin  \n",
       "0                    0               1  \n",
       "1                    1               0  \n",
       "2                    1               0  \n",
       "3                    0               0  \n",
       "4                    1               0  \n",
       "...                ...             ...  \n",
       "595207               1               1  \n",
       "595208               1               1  \n",
       "595209               0               0  \n",
       "595210               0               0  \n",
       "595211               0               0  \n",
       "\n",
       "[595212 rows x 57 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Splitting the data before applying scale\n",
    "X = ins.drop('target', axis =1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5991f62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595207</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595208</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595209</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595210</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595211</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>595212 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        target\n",
       "0            0\n",
       "1            0\n",
       "2            0\n",
       "3            0\n",
       "4            0\n",
       "...        ...\n",
       "595207       0\n",
       "595208       0\n",
       "595209       0\n",
       "595210       0\n",
       "595211       0\n",
       "\n",
       "[595212 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#target data\n",
    "y = ins[['target']]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23d86e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required library for preprocessing\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f17d034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.00000e+00, 0.00000e+00, 0.00000e+00, 5.95212e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 2.16000e+02, 5.94996e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 8.35080e+04, 5.11704e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 8.30000e+01, 5.95129e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 5.80900e+03, 5.89403e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 0.00000e+00, 5.95212e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 0.00000e+00, 5.95212e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 0.00000e+00, 5.95212e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 0.00000e+00, 5.95212e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 0.00000e+00, 5.94990e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 2.22000e+02],\n",
       "        [0.00000e+00, 0.00000e+00, 0.00000e+00, 5.94205e+05, 0.00000e+00,\n",
       "         0.00000e+00, 1.00700e+03, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 0.00000e+00, 5.89594e+05, 5.61800e+03,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 0.00000e+00, 5.94648e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 5.64000e+02, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 0.00000e+00, 5.88832e+05, 5.49500e+03,\n",
       "         7.44000e+02, 1.36000e+02, 5.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 9.43850e+04, 5.00827e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 2.01882e+05, 3.93330e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 0.00000e+00, 5.95212e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 0.00000e+00, 5.95212e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 1.30277e+05, 4.64935e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 8.92970e+04, 5.05915e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 1.07772e+05, 4.87440e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 6.04960e+04, 5.34716e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 1.01222e+05, 4.93990e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 0.00000e+00, 5.95212e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 0.00000e+00, 5.95212e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 0.00000e+00, 5.95212e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 1.10420e+05, 4.84792e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 4.20640e+04, 5.53148e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 9.99480e+04, 4.95264e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 1.95087e+05, 4.00125e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 4.85700e+03, 0.00000e+00, 5.90179e+05, 1.76000e+02,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 1.27105e+05, 4.68107e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 8.69400e+04, 5.08272e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [1.00000e+00, 0.00000e+00, 2.02783e+05, 3.92288e+05, 1.02000e+02,\n",
       "         3.80000e+01, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 5.05980e+04, 5.44321e+05, 2.93000e+02,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 4.26200e+04, 5.52592e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 7.03800e+04, 5.24832e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 1.19284e+05, 4.75928e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 1.19001e+05, 4.76211e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 1.19354e+05, 4.75858e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 1.31924e+05, 4.63288e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 6.12260e+04, 5.33986e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 1.08134e+05, 4.87078e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 8.45990e+04, 5.10613e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 7.21610e+04, 5.23051e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 1.55870e+05, 4.39342e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 9.21780e+04, 5.03034e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 1.24379e+05, 4.70833e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 1.41001e+05, 4.54208e+05, 3.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 1.30319e+05, 4.64893e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 7.70710e+04, 5.18141e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 0.00000e+00, 5.95212e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 2.21514e+05, 3.73698e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 2.65356e+05, 3.29856e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 0.00000e+00, 5.95212e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 0.00000e+00, 5.95212e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
       "        [0.00000e+00, 0.00000e+00, 0.00000e+00, 5.95212e+05, 0.00000e+00,\n",
       "         0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00]]),\n",
       " array([-23.65880348, -16.11592098,  -8.57303847,  -1.03015596,\n",
       "          6.51272654,  14.05560905,  21.59849156,  29.14137407,\n",
       "         36.68425657,  44.22713908,  51.77002159]),\n",
       " <a list of 57 BarContainer objects>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply Standardization to features matrix X\n",
    "scaler  = StandardScaler()\n",
    "X_scaled =  scaler.fit_transform(X)\n",
    "plt.hist(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ce82db",
   "metadata": {},
   "source": [
    "# Splitting the Model for LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1329e4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required library for train_test_split \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad926a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae812a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((476169, 57), (119043, 57), (476169, 1), (119043, 1))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79da4e3d",
   "metadata": {},
   "source": [
    "# Model Selection for Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fefb043",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required library for model selection\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "819ed5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09181891",
   "metadata": {},
   "source": [
    "# Evaluating the model with raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0919a931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.945810646486122"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "#test the model --> we need to pass the input data\n",
    "#predictions for trained model\n",
    "pred = model.predict(X_train)\n",
    "f1_score(y_train, pred, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2affff71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9450924331269978"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predictions for test model\n",
    "pred_test = model.predict(X_test)\n",
    "f1_score(y_test, pred_test, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ce71b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[114658,      0],\n",
       "       [  4385,      0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "039745bf",
   "metadata": {},
   "source": [
    "confusion_matrix :\n",
    "[[True Positives, False Positives]\n",
    " [False Negatives, True Negatives]]\n",
    " \n",
    " 1. True Positive - Prediction and actual values both are positive.\n",
    " 2. True Negative - Prediction and actual values both are negative.\n",
    " 3. False Positive - Prediction is positive but actual is negative.\n",
    " 4. False Negative - Prediction is negative but actual is positive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec515a25",
   "metadata": {},
   "source": [
    "In summary, a model with FP = 0 and TN = 0 might not be ideal, but its performance should be evaluated using additional metrics and in the context of our specific problem and its requirement is which customer will buy the product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b81df36d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9631645707853465"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "959b26cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98    114658\n",
      "           1       0.00      0.00      0.00      4385\n",
      "\n",
      "    accuracy                           0.96    119043\n",
      "   macro avg       0.48      0.50      0.49    119043\n",
      "weighted avg       0.93      0.96      0.95    119043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da258cb",
   "metadata": {},
   "source": [
    "we are getting score as 96% in logistic regression using given features without scaling the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b31a57ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0         573518\n",
       "1          21694\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking class balance\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3216dae",
   "metadata": {},
   "source": [
    "This is highly imbalanced data. So we should balanced the data using class_weights technique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a02bcf",
   "metadata": {},
   "source": [
    "# 1. Class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27048e85",
   "metadata": {},
   "source": [
    "Using class weights is a common and effective technique for handling highly imbalanced data in machine learning. Class weights help the model give more importance to the minority class during training, which can significantly improve the model's performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28c2796",
   "metadata": {},
   "source": [
    "# Using Class_weight parameter while creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79e6d773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = LogisticRegression(class_weight='balanced')\n",
    "model1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a591cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7394951768228155"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluation for trained model\n",
    "pred1 = model1.predict(X_train)\n",
    "f1_score(y_train, pred1, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "286d3fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7379309939913605"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluation for test model\n",
    "pred_test1 = model1.predict(X_test)\n",
    "f1_score(y_test, pred_test1, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03a23c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.63      0.76    114658\n",
      "           1       0.05      0.55      0.10      4385\n",
      "\n",
      "    accuracy                           0.62    119043\n",
      "   macro avg       0.51      0.59      0.43    119043\n",
      "weighted avg       0.94      0.62      0.74    119043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ed7cde9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6238418050620365"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a7462f",
   "metadata": {},
   "source": [
    "After using class_weights technique, we got an accuracy score is 62%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192efa54",
   "metadata": {},
   "source": [
    "# Splitting the data for Scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70e7f5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd662d9",
   "metadata": {},
   "source": [
    "# Model Selection for Logistic regression with Scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11a506f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scaled = LogisticRegression()\n",
    "model_scaled.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e923ff75",
   "metadata": {},
   "source": [
    "# Evaluating the model with scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0316979d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.945810646486122"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the model --> we need to pass the input data\n",
    "#evaluation for train model\n",
    "pred_scaled = model_scaled.predict(X_train_scaled)\n",
    "f1_score(y_train, pred_scaled, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b08403c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9450924331269978"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluation for test model\n",
    "pred_test_scaled = model_scaled.predict(X_test_scaled)\n",
    "f1_score(y_test, pred_test_scaled, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af6a564e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[114658,      0],\n",
       "       [  4385,      0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dacdb573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9631645707853465"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scaled.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "47de48d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98    114658\n",
      "           1       0.00      0.00      0.00      4385\n",
      "\n",
      "    accuracy                           0.96    119043\n",
      "   macro avg       0.48      0.50      0.49    119043\n",
      "weighted avg       0.93      0.96      0.95    119043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_test_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc20f3c",
   "metadata": {},
   "source": [
    "# PCA : Principal Compound Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbbb3e3",
   "metadata": {},
   "source": [
    "PCA is a technique widely used in machine learning to smartly reduce the dimensionality of large dataset while losing the least amount of information possible. One use of PCA is for data visualization. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "06a07fcc",
   "metadata": {},
   "source": [
    "1. PCA reduces from multiple dimensionality to minimum dimensionality. \n",
    "2. This concept is based on Eigen vectors and Eigen values.\n",
    "3. Eigen vectors produced based on projected data points for all the features.\n",
    "4. This vectors capturing the maximum variance(information) using projected data points which is called Eigen values.some of the points are overlapped and some of the points are missed in vectors.\n",
    "5. Maximum Eigen value should be taken for features extraction.\n",
    "6. Sum of Maximum Eigen values called Principal Components.\n",
    "7. Minimum amount of information will be lost using eigen values which is acceptable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b09c1a9",
   "metadata": {},
   "source": [
    "# PCA Projection to 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e685b7",
   "metadata": {},
   "source": [
    "The original data has 57 columns. The code below projects the original data which is 57 dimensional into minimum dimensions. Note that after dimensionality reduction, there usually isn’t a particular meaning assigned to each principal component. The new components are minimum dimensions of variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d61df42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2126bb7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12f11f250>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sets up the PCA object\n",
    "pca = PCA()\n",
    "\n",
    "# Transforms the training data ('tf' = 'transformed')\n",
    "x = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Plot the variance explained by each component\n",
    "plt.plot(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed1e6c2",
   "metadata": {},
   "source": [
    "# PCA without Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a566c3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(595212, 4)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make an instance of PCA\n",
    "pca = PCA(0.95)\n",
    "\n",
    "# Fit and transform the data\n",
    "X_pca = pca.fit_transform(X)\n",
    "X_pca.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc604332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9077327 , 0.02542341, 0.01103373, 0.00702688])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The variance explained by each component\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b1d96cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9512167125146926"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70d053cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of dimensions reduced from original dimensions\n",
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eef37ce",
   "metadata": {},
   "source": [
    "# Splitting data for PCA Components without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dc706f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca, X_test_pca, y_train, y_test = train_test_split(X_pca, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680547fa",
   "metadata": {},
   "source": [
    "# Model Selection for PCA Components without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0a3cb6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pca = LogisticRegression()\n",
    "model_pca.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86bf155",
   "metadata": {},
   "source": [
    "# Evaluating the model for PCA Components without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ada32b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9631645707853465"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pca.score(X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "72676b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the model --> we need to pass the input data\n",
    "#predictions\n",
    "pred_pca = model_pca.predict(X_test_pca)\n",
    "pred_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a6538784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9631645707853465"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b35d1063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98    114658\n",
      "           1       0.00      0.00      0.00      4385\n",
      "\n",
      "    accuracy                           0.96    119043\n",
      "   macro avg       0.48      0.50      0.49    119043\n",
      "weighted avg       0.93      0.96      0.95    119043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_pca))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9872a50",
   "metadata": {},
   "source": [
    "# PCA after scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a2fdc51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(595212, 47)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make an instance of PCA\n",
    "pca = PCA(0.95)\n",
    "\n",
    "# Fit and transform the data\n",
    "X_pca1 = pca.fit_transform(X_scaled)\n",
    "X_pca1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f3326f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06357069, 0.04538679, 0.03984   , 0.03478694, 0.03264271,\n",
       "       0.0307718 , 0.02791877, 0.02421807, 0.02199152, 0.02108828,\n",
       "       0.01921062, 0.01884288, 0.01784236, 0.0177124 , 0.01767554,\n",
       "       0.01765483, 0.0176436 , 0.01762084, 0.0176088 , 0.01760316,\n",
       "       0.01757921, 0.01757275, 0.01755553, 0.01753638, 0.01752075,\n",
       "       0.01751152, 0.01748893, 0.01748191, 0.01747485, 0.01746037,\n",
       "       0.01742863, 0.01741277, 0.01739953, 0.01727581, 0.01701004,\n",
       "       0.01681827, 0.01644574, 0.01599565, 0.01550622, 0.0154695 ,\n",
       "       0.01488993, 0.01389836, 0.01339226, 0.01226395, 0.01206943,\n",
       "       0.01101275, 0.01020585])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The variance explained by each component\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c74ac68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9513074979197778"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "487598d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of dimensions reduced from original dimensions\n",
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1a50a8",
   "metadata": {},
   "source": [
    "# Splitting data for PCA Components with scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2c875617",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca1, X_test_pca1, y_train, y_test = train_test_split(X_pca1, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280f34c0",
   "metadata": {},
   "source": [
    "#  Model Selection for PCA Components with scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "40768f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pca1 = LogisticRegression()\n",
    "model_pca1.fit(X_train_pca1, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d697ef45",
   "metadata": {},
   "source": [
    "# Evaluating the model for PCA Components with scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "19a381f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9631645707853465"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pca1.score(X_test_pca1, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e9c55f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the model --> we need to pass the input data\n",
    "#predictions\n",
    "pred_pca1 = model_pca1.predict(X_test_pca1)\n",
    "pred_pca1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e4146841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9631645707853465"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred_pca1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b92d5887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98    114658\n",
      "           1       0.00      0.00      0.00      4385\n",
      "\n",
      "    accuracy                           0.96    119043\n",
      "   macro avg       0.48      0.50      0.49    119043\n",
      "weighted avg       0.93      0.96      0.95    119043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_pca1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c09d70",
   "metadata": {},
   "source": [
    "After scaling the data using PCA components , we got accuracy score is 96%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39897587",
   "metadata": {},
   "source": [
    "# Class_weights due to imbalanced data after PCA with scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4274f804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0         573518\n",
       "1          21694\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fc18f0",
   "metadata": {},
   "source": [
    "Since our data is imbalanced data.So we need to balance the data using SMOTE technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "66942a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_smote = LogisticRegression(class_weight='balanced')\n",
    "model_smote.fit(X_train_pca1,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aadbe76e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7396238401328811"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_smote = model_smote.predict(X_train_pca1)\n",
    "f1_score(y_train, pred_smote, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0e54b468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7390173037400951"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_smote_test = model_smote.predict(X_test_pca1)\n",
    "f1_score(y_test, pred_smote_test, average ='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d8a66b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6252698604705863"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_smote.score(X_test_pca1, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "33941b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.63      0.76    114658\n",
      "           1       0.05      0.55      0.10      4385\n",
      "\n",
      "    accuracy                           0.63    119043\n",
      "   macro avg       0.51      0.59      0.43    119043\n",
      "weighted avg       0.94      0.63      0.74    119043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_smote_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d801c0",
   "metadata": {},
   "source": [
    "# Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7896f2a",
   "metadata": {},
   "source": [
    "#  SMOTE to oversample due to the skewness in target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c448835",
   "metadata": {},
   "source": [
    "# SMOTE : Synthetic Minority Oversampling Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabe7fb7",
   "metadata": {},
   "source": [
    "Since our dataset is imbalanced data. SMOTE is a data augmentation technique commonly used in machine learning to deal with imbalanced datatsets. It involves generating synthetic samples of the minority class by interpolating between\n",
    "existing minority class samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2d74e462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required library for balancing data\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e21e5e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "82bfe2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#smote on train and test sets\n",
    "X_train_smote, y_train_smote = sm.fit_resample(X_train_pca1, y_train)\n",
    "X_test_smote, y_test_smote = sm.fit_resample(X_test_pca1, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a0506914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((476169, 47), (917720, 47), (119043, 47), (229316, 47))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca1.shape, X_train_smote.shape, X_test_pca1.shape, X_test_smote.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f2c9c75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((476169, 1), (917720, 1), (119043, 1), (229316, 1))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_train_smote.shape, y_test.shape, y_test_smote.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5d0ffe",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9f2329a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_smote1 = LogisticRegression()\n",
    "model_smote1.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953f9218",
   "metadata": {},
   "source": [
    "# Evaluating the model for Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "caa15c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.585868408658794"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_smote1.score(X_test_smote, y_test_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "76652e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the model --> we need to pass the input data\n",
    "#predictions\n",
    "pred_smote1 = model_smote1.predict(X_test_smote)\n",
    "pred_smote1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "741d1809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.585868408658794"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_smote, pred_smote1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dab5d192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.61      0.59    114658\n",
      "           1       0.59      0.57      0.58    114658\n",
      "\n",
      "    accuracy                           0.59    229316\n",
      "   macro avg       0.59      0.59      0.59    229316\n",
      "weighted avg       0.59      0.59      0.59    229316\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_smote, pred_smote1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f3c925",
   "metadata": {},
   "source": [
    "After using SMOTE technique, we got accuracy score is 59%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01307d6",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "76391a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required library for random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ffcd66",
   "metadata": {},
   "source": [
    "# Model Seleciton for RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "767a104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf  =  RandomForestClassifier(n_estimators=10,criterion='gini',max_depth=20, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a9c0d4d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=20, n_estimators=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=20, n_estimators=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=20, n_estimators=10)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trained the model\n",
    "model_rf.fit(X_train_pca1, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b20ef55",
   "metadata": {},
   "source": [
    "# Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8d23b129",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_rf  = model_rf.predict(X_train_pca1)\n",
    "y_test_pred_rf  =  model_rf.predict(X_test_pca1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d9f1249d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9792363635599965\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_train, y_train_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dc66ee7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9471619498836555\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test , y_test_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b6ccfb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97    114658\n",
      "           1       0.06      0.03      0.04      4385\n",
      "\n",
      "    accuracy                           0.95    119043\n",
      "   macro avg       0.51      0.51      0.51    119043\n",
      "weighted avg       0.93      0.95      0.94    119043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_test_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3640f0e8",
   "metadata": {},
   "source": [
    "# Conclusions and Suggestions"
   ]
  },
  {
   "cell_type": "raw",
   "id": "896bb072",
   "metadata": {},
   "source": [
    "Machine Learning models used in this project are,\n",
    "1. Logistic Regression\n",
    "2. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a8652a",
   "metadata": {},
   "source": [
    "Both machine learning algorithms are best for classification and labelled data. The train and test data are divided and fitted into the model and passed through the machine learning. Since we have already noted the severe imbalance in the values within the target variable, we implement the SMOTE method and Class_weight technique in the dealing with this skewed value via the learn Python package. The predicted data and test data achieved the accuracy rate of,"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f05b950f",
   "metadata": {},
   "source": [
    "Logistic Regression : 96%\n",
    "Random Forest Classifier : 95%"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a4ac8db6",
   "metadata": {},
   "source": [
    "1.Establish a feedback loop between the marketing team and the claims department. Regularly share insights about customer behavior and claims data to refine marketing strategies.\n",
    "2. As the insurance business grows, the predictive model should be able to handle increaded volumes of claims.\n",
    "3. Suggest leveraging the predictive model to identify high-risk customers who are more likely to make insurance claims.Tailor marketing efforts toward these individuals to offer them relevant insurance products and services.\n",
    "4. Propose the development of insurance products that speicifically address the needs of high-risk customers. Highlight the benefits of these customized products, such as comprehensive coverage or cost-effective solutions.\n",
    "5. User the model to segment customers based on their risk profiles. Create distinct marketing strategies for different customer segments, focusing on personalized messaging and offers.\n",
    "6. Recomment cross-selling and upselling opportunities to existing customers based on their predicted claim likelihood. For example, if a customer has high likelihood of a home insurance claim, offer them a bundled home and auto insurance package.\n",
    "7. Developing strategies to retain high-risk cusotmers by offering them incentives, discounts, or loyalty programs. These strategies can help prevent customer attrition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeffa33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
